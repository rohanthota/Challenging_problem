\documentclass[journal,12pt,twocolumn]{IEEEtran}

\usepackage{setspace}
\usepackage{gensymb}
\singlespacing
\usepackage[cmex10]{amsmath}

\usepackage{amsthm}

\usepackage{mathrsfs}
\usepackage{txfonts}
\usepackage{stfloats}
\usepackage{bm}
\usepackage{cite}
\usepackage{cases}
\usepackage{subfig}

\usepackage{longtable}
\usepackage{multirow}
\usepackage{physics}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{steinmetz}
\usepackage{tikz}
\usepackage{circuitikz}
\usepackage{verbatim}
\usepackage{tfrupee}
\usepackage[breaklinks=true]{hyperref}
\usepackage{graphicx}
\usepackage{tkz-euclide}

\usetikzlibrary{calc,math}
\usepackage{listings}
    \usepackage{color}                                            %%
    \usepackage{array}                                            %%
    \usepackage{longtable}                                        %%
    \usepackage{calc}                                             %%
    \usepackage{multirow}                                         %%
    \usepackage{hhline}                                           %%
    \usepackage{ifthen}                                           %%
    \usepackage{lscape}     
\usepackage{multicol}
\usepackage{chngcntr}



\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}

\renewcommand\thesectiondis{\arabic{section}}
\renewcommand\thesubsectiondis{\thesectiondis.\arabic{subsection}}
\renewcommand\thesubsubsectiondis{\thesubsectiondis.\arabic{sub subsection}}


\hyphenation{optical networks semiconduc-tor}
\def\inputGnumericTable{}                                 %%

\lstset{
%language=C,
frame=single, 
breaklines=true,
columns=fullflexible
}
\date{March 2021}

\begin{document}

\newcommand{\BEQA}{\begin{eqnarray}}
\newcommand{\EEQA}{\end{eqnarray}}
\newcommand{\define}{\stackrel{\triangle}{=}}
\bibliographystyle{IEEEtran}
\raggedbottom
\setlength{\parindent}{0pt}
\providecommand{\mbf}{\mathbf}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\qfunc}[1]{\ensuremath{Q\left(#1\right)}}
\providecommand{\fn}[1]{\ensuremath{f\left(#1\right)}}
\providecommand{\e}[1]{\ensuremath{E\left(#1\right)}}
\providecommand{\sbrak}[1]{\ensuremath{{}\left[#1\right]}}
\providecommand{\lsbrak}[1]{\ensuremath{{}\left[#1\right.}}
\providecommand{\rsbrak}[1]{\ensuremath{{}\left.#1\right]}}
\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\providecommand{\lbrak}[1]{\ensuremath{\left(#1\right.}}
\providecommand{\rbrak}[1]{\ensuremath{\left.#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}
\providecommand{\lcbrak}[1]{\ensuremath{\left\{#1\right.}}
\providecommand{\rcbrak}[1]{\ensuremath{\left.#1\right\}}}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\providecommand{\abs}[1]{\vert#1\vert}
\providecommand{\res}[1]{\Res\displaylimits_{#1}} 
\providecommand{\norm}[1]{\lVert#1\rVert}
%\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\mtx}[1]{\mathbf{#1}}
\providecommand{\mean}[1]{E[ #1 ]}
\providecommand{\fourier}{\overset{\mathcal{F}}{ \rightleftharpoons}}
%\providecommand{\hilbert}{\overset{\mathcal{H}}{ \rightleftharpoons}}
\providecommand{\system}{\overset{\mathcal{H}}{ \longleftrightarrow}}
	%\newcommand{\solution}[2]{\textbf{Solution:}{#1}}
\newcommand{\solution}{\noindent \textbf{Solution: }}
\newcommand{\cosec}{\,\text{cosec}\,}
\providecommand{\dec}[2]{\ensuremath{\overset{#1}{\underset{#2}{\gtrless}}}}
\newcommand{\myvec}[1]{\ensuremath{\begin{pmatrix}#1\end{pmatrix}}}
\newcommand{\mydet}[1]{\ensuremath{\begin{vmatrix}#1\end{vmatrix}}}
\numberwithin{equation}{subsection}
\makeatletter
\@addtoreset{figure}{problem}
\makeatother
\let\StandardTheFigure\thefigure
\let\vec\mathbf
\renewcommand{\thefigure}{\theproblem}
\def\putbox#1#2#3{\makebox[0in][l]{\makebox[#1][l]{}\raisebox{\baselineskip}[0in][0in]{\raisebox{#2}[0in][0in]{#3}}}}
     \def\rightbox#1{\makebox[0in][r]{#1}}
     \def\centbox#1{\makebox[0in]{#1}}
     \def\topbox#1{\raisebox{-\baselineskip}[0in][0in]{#1}}
     \def\midbox#1{\raisebox{-0.5\baselineskip}[0in][0in]{#1}}
\vspace{3cm}
\title{AI 1103 - Challenging Problem 11}
\author{T. Rohan \\ CS20BTECH11064}
\maketitle
\newpage
\bigskip
\renewcommand{\thefigure}{\theenumi}
\renewcommand{\thetable}{\theenumi}
Download all latex codes from 
\begin{lstlisting}
https://github.com/rohanthota/Challenging_problem/main.tex
\end{lstlisting}
\section{Problem}
(UGC/MATH 2018 (June set-a)-Q.106) Let ${X_i}_{i \geq 1}$ be a sequence of i.i.d. random variables with $E(X_i)=0$ and $V(X_i)=1$. Which of the following are true?
\vspace{0.2cm}
\begin{enumerate}
    \item $\dfrac{1}{n} \sum_{i=1}^n X_i^2 \to 0$ in probability 
    \item $\dfrac{1}{n^{3/4}} \sum_{i=1}^n X_i \to 0$ in probability 
    \item $\dfrac{1}{n^{1/2}} \sum_{i=1}^n X_i \to 0$ in probability 
    \item $\dfrac{1}{n} \sum_{i=1}^n X_i^2 \to 1$ in probability
\end{enumerate}

\section{\emph{Solution}}
CONVERGENCE IN DISTRIBUTION:
A sequence of random variables $Y$, $Y_1$, $Y_2 \ldots$   converges in distribution to a random variable $Y$, if

\begin{align}
    \lim_{n \to \infty}F_{X_{n}} (a) = F_{X} (a)  \text{  }\forall a \in \mathbb{R}.
\end{align}

CONVERGENCE IN PROBABILITY:
A sequence of random variables $Y$, $Y_1$, $Y_2 \ldots$ is said to converge in probability to $Y$, if
\begin{align}
    \lim_{n \to \infty}\pr{\abs{Y_n - Y} > \epsilon} = 0  \text{  }\forall \epsilon > 0.
\end{align}




THEOREM: 
If
\begin{math}
 {Y_n} \to Y \text{ in probability, }{Y_n} \to Y \text{ in distribution.}
\end{math}

STRONG LAW OF LARGE NUMBERS: 
Let $X_1$, $X_2$, \ldots $X_n$ be i.i.d. random variables with expected value $E(X_i)=\mu < \infty$, then,

\begin{align}
    \lim_{n \to \infty}\pr{\left|\dfrac{1}{n}\sum_{i=1}^n X_i - \mu \right|\geq \epsilon}=0
\end{align}
Or, 
\begin{math}
    \dfrac{1}{n}\sum_{i=1}^n X_i
\end{math}
converges in probability to $\mu$.

CENTRAL LIMIT THEOREM(CLT):

Let $X_1$, $X_2$, \ldots $X_n$ be i.i.d. random variables with expected value $E(X_i)=\mu < \infty$  and $0 < V(X_i)=\sigma^2 < \infty$. Then the random variable 

\begin{align}
    Z_n = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}} = \frac{X_1 + X_2 + \ldots + X_n - n\mu}{\sqrt{n}\sigma}
\end{align}

converges in distribution to the standard normal random variable as n goes to infinity, that is
\begin{align}
    \lim_{n \to \infty}\pr{Z_n \leq a} = \Phi(a)   \text{        }\forall a \in \mathbb{R}.
\end{align}
where $\Phi(a)$ is the standard normal CDF.


\begin{enumerate}
\item Let $F_{X_i}(x)$ be the c.d.f. for the random variable $X_i$.
As ${X_i}$ is sequence of i.i.d. random variables, it follows the following conditions $\forall x,x_i \in \mathbb{R}$:
    \begin{enumerate}
        \item \begin{math}F_{X_1}(x)=F_{X_2}(x)=\ldots=F_{X_n}(x)=F_X(x)\end{math}
        \item \begin{math}F_{X_1,\ldots X_n}(x_1\ldots x_n)=F_X(x_1)F_X(x_2)\ldots F_X(x_n)\end{math}
    \end{enumerate}
where $F_X(x)$ is the c.d.f. of $X_i$.

Let $Y_i=X_i^2$. Then for $y \geq 0$,
\begin{align}
    F_{Y_i}(y)&=\pr{Y_i \leq y}\\
    \implies F_{Y_i}(y)&=\pr{X_i^2 \leq y}\\
    \implies F_{Y_i}(y)&=\pr{-\sqrt{y} \leq X_i \leq \sqrt{y}}\label{eqref}\\
    \implies F_{Y_i}(y)&=\pr{X_i \leq \sqrt{y}}-\pr{X_i \leq -\sqrt{y}}\\
    \implies F_{Y_i}(y)&=F_{X_i}(\sqrt{y})-F_{X_i}(-\sqrt{y})
\end{align}
Using condition (a),
\begin{align} 
    F_{Y_i}(y)&=F_X(\sqrt{y})-F_X(-\sqrt{y})\label{eqY}
\end{align}
From \eqref{eqY},
\begin{align} 
    F_{X_1^2}(y)=F_{X_2^2}(y)=\ldots=F_{X_n^2}(y)=F_Y(y)\label{condnA}
\end{align}
where $F_Y(y)$ is the c.d.f. of $Y_i=X_i^2$.

Now, for $y_i\geq0$, consider
\begin{align}
    &F_{Y_1,Y_2,\ldots,Y_n}(y_1,y_2,\ldots,y_n) \nonumber\\
    &=\pr{Y_1 \leq y_1,Y_2 \leq y_2,\ldots,Y_n \leq y_n}
\end{align}
\begin{align}
    &=\pr{X_1^2 \leq y_1,X_2^2 \leq y_2,\ldots,X_n^2 \leq y_n}\\
    &=\pr{-\sqrt{y_1} \leq X_1 \leq \sqrt{y_1},-\sqrt{y_2} \leq X_2 \leq \sqrt{y_2}, \nonumber\\
    &\ldots,-\sqrt{y_n} \leq X_n \leq \sqrt{y_n}}
\end{align}
Since $X_1,X_2,\ldots,X_n$ are independent,
\begin{align}
    &F_{Y_1,Y_2,\dots,Y_n}(y_1,y_2,\dots,y_n)= \nonumber\\
    &\pr{-\sqrt{y_1} \leq X_1 \leq \sqrt{y_1}} \pr{-\sqrt{y_2} \leq X_2 \leq \sqrt{y_2}} \nonumber\\
    &\hspace{2cm} \dots \pr{-\sqrt{y_n} \leq X_n \leq \sqrt{y_n}}
\end{align}
From \eqref{eqref} and \eqref{condnA},
\begin{align}
    &F_{Y_1,Y_2,\dots,Y_n}(y_1,y_2,\dots,y_n) \nonumber \\
    &=F_{Y_1}(y_1) F_{Y_2}(y_2)\dots F_{Y_n}(y_n)\\
    &=F_Y(y_1) F_Y(y_2) \dots F_Y(y_n)
\end{align}
So,
\begin{align} \label{condnB}
    F_{X_1^2,X_2^2,\dots,X_n^2}&(y_1,y_2,\dots,y_n)\nonumber \\
    &=F_Y(y_1)F_Y(y_1)\dots F_Y(y_n)
\end{align}
By \eqref{condnA} and \eqref{condnB}, ${X_i^2}$ must also be a sequence of i.i.d. random variables.

We know,
\begin{align}
    E(X_i^2)=V(X_i)+(E(X_i))^2
\end{align}
Putting given values, we get,
\begin{align} 
    E(X_i^2)&=1 \label{muval}
\end{align}

From S.L.L.N,  
\begin{math}\dfrac{1}{n}\sum_{i=1}^n X_i^2\end{math} converges in probability to $E(X_i^2)=1$.

Therefore, option 1 is incorrect.

\item Now, we define
\begin{align}
    Y_n=\dfrac{1}{n^{3/4}}\sum_{i=1}^n X_i
\end{align}
Then,
\begin{align}
    E(Y_n) &= \dfrac{1}{n^{3/4}}E\brak{\sum_{i=1}^n X_i} \\
    \implies E(Y_n) &= \dfrac{1}{n^{3/4}}\brak{E(X_1)+E(X_2) \ldots E(X_n)}
\end{align}
Since $E(X_i) = 0$
\begin{align}
    E(Y_n) &= \dfrac{1}{n^{3/4}}\brak{0} =0
\end{align}
Now,
\begin{align}
    V(Y_n) &= V\brak{\dfrac{1}{n^{3/4}}\sum_{i=1}^n X_i} \\
    \implies V(Y_n) &= \dfrac{1}{n^{3/2}}V\brak{X_1+X_2+ \dots +X_n}
\end{align}
As $X_1, X_2, \cdot \cdot \cdot X_n$ are independent of each other,
\begin{align}
    V(Y_n) &= \dfrac{1}{n^{3/2}}\brak{V(X_1)+V(X_2)+ \dots +V(X_n)}
\end{align}
Since $V(X_i) = 1$
\begin{align}
    V(Y_n)=\dfrac{1}{n^{3/2}}\brak{1+1+ \ldots +1}=\dfrac{1}{n^{3/2}}\times n=\dfrac{1}{n^{1/2}}
\end{align}
Now for any $\epsilon>0$, consider the probability
\begin{align}
    \pr{|Y_n-0|\geq \epsilon}=\pr{|Y_n-E(Y_n)|\geq \epsilon}
\end{align}
Applying Chebyschev's inequality here, we get,
\begin{align}
    \pr{|Y_n-0|\geq \epsilon} \leq \dfrac{V(Y_n)}{\epsilon^2} = \dfrac{1}{n^{1/2}\epsilon^2}
\end{align}
So,
\begin{align}
    \lim_{n \to \infty}\pr{|Y_n-0|\geq \epsilon} \leq \lim_{n \to \infty }\dfrac{1}{n^{1/2}\epsilon^2}=0\\
    \implies \lim_{n \to \infty}\pr{\left | \dfrac{1}{n^{3/4}}\sum_{i=1}^n X_i - 0 \right|\geq \epsilon}=0
\end{align}
So, $\dfrac{1}{n^{3/4}}\sum_{i=1}^n X_i \to 0$ in probability.\\
Thus, option 2 is correct.

\item The option states that
\begin{math}
 \dfrac{1}{n^{1/2}} \sum_{i=1}^n X_i \to 0
\end{math} 
in probability. This statement implies that $\dfrac{1}{n^{1/2}} \sum_{i=1}^n X_i \to 0$ in distribution, from the theorem.

Writing the random variable $Z_n$ from CLT, for the i.i.d random variables,
\begin{align}
    Z_n &= \frac{X_1 + X_2 + \ldots + X_n - n\mu}{\sqrt{n}\sigma}\\
    &= \frac{X_1 + X_2 + \ldots + X_n}{\sqrt{n}}
\end{align}
\begin{align}
    &= \dfrac{1}{n^{1/2}} \sum_{i=1}^n X_i
\end{align}
Since $\mu = 0$ and $\sigma = 1$.

According to Central limit theorem, 
\begin{align}
    Z_n \to Z, \text{where, } Z \sim N(0,1)
\end{align}
which is not what the option states. Therefore, option 3 is incorrect.

\item As proved in option (1), $\dfrac{1}{n}\sum_{i=1}^n X_i^2 \to 1$ in probability. So option 4 is correct.
\end{enumerate}
Therefore, options 2 and 4 are correct.
\end{document}
